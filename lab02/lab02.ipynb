{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:15.363920Z",
     "start_time": "2018-02-02T15:15:14.337886Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly as py\n",
    "import plotly.express as px\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this lecture we examine the process of Exploratory Data Analysis (EDA).  Often you will acquire or even be given a collection of data in order to conduct some analysis or answer some questions. The first step in using that data is to ensure that it is in the correct form (cleaned) and that you understand its properties and limitations (EDA).  Often as you explore data through EDA you will identify additional transformations that may be required before the data is ready for analysis.\n",
    "\n",
    "In this notebook we obtain crime data from the city of Berkeley's public records.  Ultimately, our goal might be to understand policing patterns but before we get there we must first clean and understand the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Data\n",
    "\n",
    "To begin this analysis we want to get data about crimes in Berkeley.  Remarkably, the city of Berkeley maintains an [Open Data Portal](https://data.cityofberkeley.info/) for citizens to access data about the city.  We will be examining the:\n",
    "\n",
    "1. [Call Data](https://data.cityofberkeley.info/Public-Safety/Berkeley-PD-Calls-for-Service/k2nh-s5h5)\n",
    "1. [Stop Data](https://data.cityofberkeley.info/Public-Safety/Berkeley-PD-Stop-Data-October-1-2020-Present-/ysvs-bcge)\n",
    "\n",
    "Fortunately, this data is also relatively well document with detailed descriptions of what it contains. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lecture, I am downloading a pre-extracted version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_cache(data_url, file, data_dir=\"data\", force=False):\n",
    "    \"\"\"\n",
    "    Download and cache a url and return the file object.\n",
    "    \n",
    "    data_url: the web address to download\n",
    "    file: the file in which to save the results.\n",
    "    data_dir: (default=\"data\") the location to save the data\n",
    "    force: if true the file is always re-downloaded \n",
    "    \n",
    "    return: The pathlib.Path object representing the file.\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    from pathlib import Path\n",
    "    import time \n",
    "    data_dir = Path(data_dir)\n",
    "    data_dir.mkdir(exist_ok = True)\n",
    "    file_path = data_dir / Path(file)\n",
    "    # If the file already exists and we want to force a download then\n",
    "    # delete the file first so that the creation date is correct.\n",
    "    if force and file_path.exists():\n",
    "        file_path.unlink()\n",
    "    if force or not file_path.exists():\n",
    "        print('Downloading...', end=' ')\n",
    "        resp = requests.get(data_url)\n",
    "        with file_path.open('wb') as f:\n",
    "            f.write(resp.content)\n",
    "        print('Done!')\n",
    "        last_modified_time = time.ctime(file_path.stat().st_mtime)\n",
    "    else:\n",
    "        last_modified_time = time.ctime(file_path.stat().st_mtime)\n",
    "        print(\"Using cached version that was downloaded (UTC):\", last_modified_time)\n",
    "    return file_path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_file = fetch_and_cache(\"https://raw.githubusercontent.com/DS-100/oreilly-bootcamp/main/data/calls.csv\",\n",
    "                             \"calls.csv\")\n",
    "stops_file = fetch_and_cache(\"https://raw.githubusercontent.com/DS-100/oreilly-bootcamp/main/data/stops.json\",\n",
    "                             \"stops.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Most data has bad documentation:\n",
    "\n",
    "Unfortunately, data is seldom well documented and when it is you may not be able to trust the documentation. It is therefore critical that when we download the data we investigate the fields and verify that it reflects the assumptions made in the documentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the data\n",
    "\n",
    "Now that we have obtained the data we want to understand its:\n",
    "\n",
    "* **Structure** -- the \"shape\" of a data file\n",
    "* **Granularity** -- how fine/coarse is each datum\n",
    "* **Scope** -- how (in)complete is the data\n",
    "* **Temporality** -- how is the data situated in time\n",
    "* **Faithfulness** -- how well does the data capture \"reality\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure\n",
    "\n",
    "Before we even begin to load the data it often helps to understand a little about the high-level structure:\n",
    "\n",
    "1. How much data do I have?\n",
    "1. How is it formatted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How big is the data?\n",
    "\n",
    "I often like to start my analysis by getting a rough estimate of the size of the data.  This will help inform the tools I use and how I view the data.  If it is relatively small I might use a text editor or a spreadsheet to look at the data.  If it is larger, I might jump to more programmatic exploration or even used distributed computing tools.\n",
    "\n",
    "However here we will use python tools to probe the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:18.961511Z",
     "start_time": "2018-02-02T15:15:18.955308Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(calls_file, \"is\",  os.path.getsize(calls_file) / 1e6, \"MB\")\n",
    "print(stops_file, \"is\", os.path.getsize(stops_file) / 1e6, \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the files are relatively small and we could comfortable examine them in a text editors.  (Personally, I like *sublime* or *emacs* but others may have a different *vi*ew.). \n",
    "\n",
    "In listing the files I noticed that the names suggest that they are all text file formats:\n",
    "* **CSV**: Comma separated values is a very standard table format.\n",
    "* **JSON**: JavaScript Object Notation is a very standard semi-structured file format used to store nested data.\n",
    "\n",
    "We will dive into the formats in a moment.  However because these are text data I might also want to investigate the number of lines which often correspond to records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:18.993584Z",
     "start_time": "2018-02-02T15:15:18.989848Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(calls_file, \"r\") as f:\n",
    "    print(calls_file, \"is\", sum(1 for l in f), \"lines.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:18.993584Z",
     "start_time": "2018-02-02T15:15:18.989848Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(stops_file, \"r\") as f:\n",
    "    print(stops_file, \"is\", sum(1 for l in f), \"lines.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### What is the file format?  (Can we trust extensions?)\n",
    "\n",
    "We already noticed that the files end in `csv` and `json` which suggests that these are comma separated and javascript object files respectively.  However, we can't always rely on the naming as this is only a convention.  For example, here we picked the name of the file when downloading based on some hints in the URL.\n",
    "\n",
    "\n",
    "\n",
    "**Often files will have incorrect extensions or no extension at all.**\n",
    "\n",
    "Let's assume that these are text files (and do not contain binary encoded data) so we can print a \"few lines\" to get a better understanding of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calls_file, \"======================\")\n",
    "with open(calls_file, \"r\") as f:\n",
    "    for i in range(5):\n",
    "        print(i, \"\\t\", repr(f.readline()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are some observations about `Calls` data?\n",
    "\n",
    "\n",
    "<details><summary>Click for Solution</summary>\n",
    "\n",
    "1. It appears to be in comma separated value (CSV) format.\n",
    "1. First line contains the column headings.\n",
    "1. There are lots of **new-line** `\\n` characters:\n",
    "    * at the ends of lines (delimiting records?)\n",
    "    * *within records* as part of addresses.\n",
    "1. There are **\"quoted\"** strings in the `Block_Location` column:\n",
    "```\n",
    "\"2500 LE CONTE AVE\n",
    "Berkeley, CA\n",
    "(37.876965, -122.260544)\"\n",
    "```\n",
    "these are going to be difficult.  What are the implications on our earlier line count calculations?\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stops_file, \"======================\")\n",
    "with open(stops_file, \"r\") as f:\n",
    "    for i in range(40):\n",
    "        print(i, \"\\t\", repr(f.readline()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that I used the `repr` function to return the raw string with special characters.  This is helpful in deducing the file format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Loading the Data\n",
    "\n",
    "We will now attempt to load the data into python.  We will be using the Pandas dataframe library for basic tabular data analysis.  Fortunately, the Pandas library has some relatively sophisticated functions for loading data. \n",
    "\n",
    "Because the file appears to be a relatively well formatted CSV we will attempt to load it directly and allow the Pandas Library to deduce column headers.  (Always check that first row and column look correct after loading.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls = pd.read_csv(calls_file, on_bad_lines=\"warn\")\n",
    "calls.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = pd.read_json(stops_file)\n",
    "stops.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking more into the structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.122345Z",
     "start_time": "2018-02-02T15:15:19.118071Z"
    }
   },
   "outputs": [],
   "source": [
    "calls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# EDA on Calls Data\n",
    "\n",
    "Often the first step of EDA is addressing any obvious issues with the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "What are some issues with this data?\n",
    "\n",
    "<details><summary>Click for Solution</summary>\n",
    "\n",
    "1. `EVENTDT` -- Contain the incorrect time stamp\n",
    "1. `EVENTTM` -- Contains the time in 24 hour format (What timezone?)\n",
    "1. `CVDOW` -- Appears to be some encoding of the day of the week (see data documentation).\n",
    "1. `InDbDate` -- Appears to be correctly formatted and appears pretty consistent in time.\n",
    "1. **`Block_Location` -- Errr, what a mess!  newline characters, and Geocoordinates all merged!!  Fortunately, this field was \"quoted\" otherwise we would have had trouble parsing the file. (why?)**\n",
    "1. `BLKADDR` -- This appears to be the address in Block Location.\n",
    "1. `City` and `State` seem redundant given this is supposed to be the city of Berkeley dataset.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "\n",
    "Often I will go column by column looking for things that might be interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Case Numbers\n",
    "\n",
    "These are probably the primary key but we want to verify that and also examine how they were assigned. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary Key\n",
    "\n",
    "Case numbers are probably used internally to track individual cases and my reference other data we don't have access to.  However, it is possible that multiple calls could be associated with the same case.  Let's see if the case numbers are all unique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.849003Z",
     "start_time": "2018-02-02T15:15:19.845047Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"There are\", calls['CASENO'].unique().shape[0], \"unique case numbers.\")\n",
    "print(\"There are\", calls.shape[0], \"calls in the table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Numbers and Time \n",
    "\n",
    "Sometimes something as simple as a case number and when it was created can reveal something about how the case was processed.\n",
    "\n",
    "However we need to clean up the date and time encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging `EVENTDT` and `EVENTTM` to construct a single date time object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_date_time(dates, times):\n",
    "    from datetime import datetime\n",
    "    return pd.concat([dates, times], axis=1).apply(\n",
    "        lambda r: datetime.combine(r[0], r[1]), axis=1)\n",
    "\n",
    "dates = pd.to_datetime(calls['EVENTDT']).dt.date\n",
    "times = pd.to_datetime(calls['EVENTTM']).dt.time\n",
    "calls['date'] = combine_date_time(dates, times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the cases numbers in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(calls, x=\"date\", y=\"CASENO\", hover_name=\"CVLEGEND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like to use interactive plotting tools so I can hover the mouse over the plot and read the values.  The cufflinks library adds plotly support to Pandas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What might we be observing?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "--- \n",
    "\n",
    "## The Offense Field\n",
    "\n",
    "The Offense field appears to contain the specific crime being reported.  As nominal data we might want to see a summary constructed by computing counts of each offense type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(calls, x=\"OFFENSE\").update_xaxes(categoryorder='total descending')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## CVLEGEND\n",
    "\n",
    "The CVLEGEND field provides the broad category of crime and is a good mechanism to group potentially similar crimes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:32.695890Z",
     "start_time": "2018-02-02T15:15:30.443888Z"
    }
   },
   "outputs": [],
   "source": [
    "px.histogram(calls, x=\"CVLEGEND\").update_xaxes(categoryorder='total descending')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when we group by the crime time we see that **larceny** emerges as one of the top crimes.  Larceny is essentially stealing -- taking someone else stuff without force."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the relatinoship between Offense and CVLegend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvt = pd.pivot_table(calls, values=\"CASENO\", index=\"OFFENSE\", columns=\"CVLEGEND\", aggfunc=\"count\", fill_value=0)\n",
    "pvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(pvt.to_numpy().T, x=pvt.index, y=pvt.columns, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## Time Fields\n",
    "\n",
    "We already started to look at where this data is situated in time and how calls were reported during the reporting period.  Now lets examine how calls relate to day of the week and even the type of crime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we need to do some data cleaning.  `CVDOW` contains the day of the week.  According to the documentation `CVDOW=0` is Sunday, `CVDOW=1` is Monday, ...,  Therefore we can make a series to decode the day of the week for each record and join that series with the calls data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.160218Z",
     "start_time": "2018-02-02T15:15:19.152680Z"
    }
   },
   "outputs": [],
   "source": [
    "dow = pd.Series([\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"], name=\"Day\")\n",
    "dow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.224038Z",
     "start_time": "2018-02-02T15:15:19.189254Z"
    }
   },
   "outputs": [],
   "source": [
    "calls = pd.merge(calls, pd.DataFrame(dow), left_on='CVDOW', right_index=True).sort_index()\n",
    "calls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(calls, \"Day\", category_orders={\"Day\": dow})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "### How about temporal patterns within a day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:28.279664Z",
     "start_time": "2018-02-02T15:15:28.263705Z"
    }
   },
   "outputs": [],
   "source": [
    "calls['hour_of_day'] = (\n",
    "    calls['date'].dt.hour * 60 + calls['date'].dt.minute ) / 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:28.426935Z",
     "start_time": "2018-02-02T15:15:28.281805Z"
    }
   },
   "outputs": [],
   "source": [
    "ff.create_distplot([calls['hour_of_day']], group_labels=[\"Hour\"],bin_size=.5, show_rug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Observations?**\n",
    "\n",
    "<details><summary>Click for Solution</summary>\n",
    "    \n",
    "In the above plot we see the standard pattern of limited activity early in the morning around here 6:00AM.  We also see that large spikes at 0 and 12.  Why?\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "\n",
    "### Stratified Analysis\n",
    "\n",
    "To better understand the time of day a report occurs we could stratify the analysis by the day of the week.  To do this we will use box plots.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.violin(calls.sort_values(\"CVDOW\"), y=\"hour_of_day\", x=\"Day\", box=True, points=\"all\", hover_name=\"CVLEGEND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Location\n",
    "\n",
    "The block location contains the lat/lon coordinates and I might want to use these to analyze the location of each request.  Let's try to extract the GPS coordinates using regular expressions (we will cover regular expressions in future lectures):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.230720Z",
     "start_time": "2018-02-02T15:15:19.225971Z"
    }
   },
   "outputs": [],
   "source": [
    "calls['Block_Location'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.268222Z",
     "start_time": "2018-02-02T15:15:19.233193Z"
    }
   },
   "outputs": [],
   "source": [
    "calls_lat_lon = (\n",
    "    # Remove newlines\n",
    "    calls['Block_Location'].str.replace(\"\\n\", \"\\t\") \n",
    "    # Extract Lat and Lon using regular expression\n",
    "    .str.extract(\".*\\((?P<Lat>\\d*\\.\\d*)\\, (?P<Lon>-?\\d*\\.\\d*)\\)\", expand=True)\n",
    "    .astype(float)\n",
    ")\n",
    "calls_lat_lon.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block of code joins the extracted Latitude and Longitude fields with the calls data.  Notice that we actually drop these fields before joining.  This is to enable repeated invocation of this cell even after the join has been completed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join in the the latitude and longitude data\n",
    "calls = calls.join(calls_lat_lon)\n",
    "# calls[[\"Lat\", \"Lon\"]] = calls_lat_lon\n",
    "calls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.set_mapbox_access_token(open(\"mapbox.token\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.density_mapbox(calls, lat='Lat', lon='Lon', radius=7, zoom=12,\n",
    "                        mapbox_style=\"stamen-terrain\", height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. Why are all the calls located on the street and at often at intersections?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_mapbox(calls, lat=\"Lat\", lon=\"Lon\", color=\"CVLEGEND\", size_max=10, zoom=12, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You Explore\n",
    "\n",
    "What else do you see in this data?  Try playing with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# EDA on Stops Data\n",
    "\n",
    "## You try\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# EDA on Stops Data\n",
    "\n",
    "Often the first step of EDA is addressing any obvious issues with the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "--- \n",
    "\n",
    "## Record Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique Records:\", len(stops['lea_record_id'].unique()))\n",
    "print(\"Total Records:\", len(stops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(stops[\"lea_record_id\"].value_counts(), log_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "### Temporality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(stops['date_of_stop']).dt.date\n",
    "times = pd.to_datetime(stops['time_of_stop']).dt.time\n",
    "stops['date'] = combine_date_time(dates, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops['record_num'] = stops['lea_record_id'].str.replace(\"BPD\", \"\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(stops, x=\"date\", y=\"record_num\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Person Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(stops, x=\"person_number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Perceived Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(stops, x='perceived_race_or_ethnicity') # log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(stops[~stops[\"perceived_race_or_ethnicity\"].str.contains(\"\\|\")], x='perceived_race_or_ethnicity') # log_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationship to whether the race was perceived prior to the stop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(stops[~stops[\"perceived_race_or_ethnicity\"].str.contains(\"\\|\")], \n",
    "             x='perceived_race_or_ethnicity', color=\"raceperceivedpriortostop\", barmode=\"group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## City of Residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(stops, x=\"city_of_residence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cities = (stops\n",
    "              .groupby(\"city_of_residence\", as_index=False).size()\n",
    "              .sort_values(\"size\", ascending=False)\n",
    "              .head(20))\n",
    "px.bar(top_cities, x=\"city_of_residence\", y=\"size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "##  Understanding Age and Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(stops, nbins=20, \n",
    "             x=\"perceived_age\", color=\"perceived_gender\",  \n",
    "             barmode=\"overlay\", histnorm=\"percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
